{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000\n",
    "np.random.seed(1)\n",
    "data0 = np.random.normal(0, 1.25, N)\n",
    "data1 = np.random.normal(0, 1, int(N/100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_generator(numsamples=1000):\n",
    "    n0 = int(0.7*len(data0))\n",
    "    n1= int(0.7*len(data1))\n",
    "    if np.random.binomial(1, 0.5):\n",
    "        # return class 0\n",
    "        i = np.random.randint(0, n0-60)\n",
    "        yield data0[i:i+60], 0\n",
    "    else:\n",
    "        # return class 1\n",
    "        i = np.random.randint(0, n1-60)\n",
    "        yield data1[i:i+60], 1\n",
    "        \n",
    "def test_generator():\n",
    "    d0 = data0[-int(0.3*len(data0)):]\n",
    "    d1 = data1[-int(0.3*len(data1)):]\n",
    "    for i in range(len(d0)//60-1):\n",
    "        yield d0[60*i:60*(i+1)], 0\n",
    "    for i in range(len(d1)//60-1):\n",
    "        yield d1[60*i:60*(i+1)], 1\n",
    "        \n",
    "def train_input_fn():\n",
    "    dataset = tf.data.Dataset.from_generator(train_generator, (tf.float32, tf.int32),\n",
    "                                            ((60), ())).batch(100).prefetch(10)\n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "def test_input_fn():\n",
    "    dataset = tf.data.Dataset.from_generator(test_generator, (tf.float32, tf.int32),\n",
    "                                            ((60), ())).batch(100).prefetch(10)\n",
    "    return dataset.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    labels_oh = tf.one_hot(labels, 2)\n",
    "    # 60\n",
    "    net = tf.expand_dims(features, 2)\n",
    "    net = tf.layers.conv1d(net, 8, 3, activation=tf.nn.relu)\n",
    "    net = tf.layers.max_pooling1d(net, 2, 2)\n",
    "    # 30\n",
    "    net = tf.layers.conv1d(net, 16, 3, activation=tf.nn.relu)\n",
    "    net = tf.layers.max_pooling1d(net, 2, 2)\n",
    "    # 15\n",
    "    net = tf.layers.conv1d(net, 32, 3, activation=tf.nn.relu)\n",
    "    net = tf.layers.max_pooling1d(net, 3, 3)\n",
    "    # 5\n",
    "    net = tf.layers.conv1d(net, 64, 3, activation=tf.nn.relu)\n",
    "    flat = tf.layers.flatten(net)\n",
    "    logits = tf.layers.dense(flat, 2)\n",
    "    predicted_class = tf.argmax(logits, 1)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions={\"class_ids\":predicted_class[:, tf.newaxis],\n",
    "                    \"probabilities\":tf.nn.softmax(logits),\n",
    "                    \"logits\":logits}\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "    \n",
    "    loss = tf.losses.softmax_cross_entropy(labels_oh, logits)\n",
    "    # compute eval metrics\n",
    "    accuracy = tf.metrics.accuracy(labels=labels, predictions=predicted_class)\n",
    "    metrics={\"accuracy\":accuracy}\n",
    "    tf.summary.scalar(\"accuracy\", accuracy[1])\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            mode, loss=loss, eval_metric_ops=metrics\n",
    "        )\n",
    "    optimizer = tf.train.MomentumOptimizer(0.01, 0.9)\n",
    "    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'logs', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x181d99abe0>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.Estimator(model_fn=model_fn, params={}, model_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainspec = tf.estimator.TrainSpec(train_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalspec = tf.estimator.EvalSpec(test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m\n",
       "Train and evaluate the `estimator`.\n",
       "\n",
       "This utility function trains, evaluates, and (optionally) exports the model by\n",
       "using the given `estimator`. All training related specification is held in\n",
       "`train_spec`, including training `input_fn` and training max steps, etc. All\n",
       "evaluation and export related specification is held in `eval_spec`, including\n",
       "evaluation `input_fn`, steps, etc.\n",
       "\n",
       "This utility function provides consistent behavior for both local\n",
       "(non-distributed) and distributed configurations. Currently, the only\n",
       "supported distributed training configuration is between-graph replication.\n",
       "\n",
       "Overfitting: In order to avoid overfitting, it is recommended to set up the\n",
       "training `input_fn` to shuffle the training data properly. It is also\n",
       "recommended to train the model a little longer, say multiple epochs, before\n",
       "performing evaluation, as the input pipeline starts from scratch for each\n",
       "training. It is particularly important for local training and evaluation.\n",
       "\n",
       "Stop condition: In order to support both distributed and non-distributed\n",
       "configuration reliably, the only supported stop condition for model\n",
       "training is `train_spec.max_steps`. If `train_spec.max_steps` is `None`, the\n",
       "model is trained forever. *Use with care* if model stop condition is\n",
       "different. For example, assume that the model is expected to be trained with\n",
       "one epoch of training data, and the training `input_fn` is configured to throw\n",
       "`OutOfRangeError` after going through one epoch, which stops the\n",
       "`Estimator.train`. For a three-training-worker distributed configuration, each\n",
       "training worker is likely to go through the whole epoch independently. So, the\n",
       "model will be trained with three epochs of training data instead of one epoch.\n",
       "\n",
       "Example of local (non-distributed) training:\n",
       "```python\n",
       "# Set up feature columns.\n",
       "categorial_feature_a = categorial_column_with_hash_bucket(...)\n",
       "categorial_feature_a_emb = embedding_column(\n",
       "    categorical_column=categorial_feature_a, ...)\n",
       "...  # other feature columns\n",
       "\n",
       "estimator = DNNClassifier(\n",
       "    feature_columns=[categorial_feature_a_emb, ...],\n",
       "    hidden_units=[1024, 512, 256])\n",
       "\n",
       "# Or set up the model directory\n",
       "#   estimator = DNNClassifier(\n",
       "#       config=tf.estimator.RunConfig(\n",
       "#           model_dir='/my_model', save_summary_steps=100),\n",
       "#       feature_columns=[categorial_feature_a_emb, ...],\n",
       "#       hidden_units=[1024, 512, 256])\n",
       "\n",
       "# Input pipeline for train and evaluate.\n",
       "def train_input_fn: # returns x, y\n",
       "  # please shuffle the data.\n",
       "  pass\n",
       "def eval_input_fn_eval: # returns x, y\n",
       "  pass\n",
       "\n",
       "train_spec = tf.estimator.TrainSpec(input_fn=train_input_fn, max_steps=1000)\n",
       "eval_spec = tf.estimator.EvalSpec(input_fn=eval_input_fn)\n",
       "\n",
       "tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
       "```\n",
       "\n",
       "Example of distributed training:\n",
       "\n",
       "Regarding the example of distributed training, the code above can be used\n",
       "without a change (Please do make sure that the `RunConfig.model_dir` for all\n",
       "workers is set to the same directory, i.e., a shared file system all workers\n",
       "can read and write). The only extra work to do is setting the environment\n",
       "variable `TF_CONFIG` properly for each worker correspondingly.\n",
       "\n",
       "Also see: https://www.tensorflow.org/deploy/distributed\n",
       "\n",
       "Setting environment variable depends on the platform. For example, on Linux,\n",
       "it can be done as follows (`$` is the shell prompt):\n",
       "```\n",
       "$ TF_CONFIG='<replace_with_real_content>' python train_model.py\n",
       "```\n",
       "\n",
       "For the content in `TF_CONFIG`, assume that the training cluster spec looks\n",
       "like:\n",
       "```\n",
       "cluster = {\"chief\": [\"host0:2222\"],\n",
       "           \"worker\": [\"host1:2222\", \"host2:2222\", \"host3:2222\"],\n",
       "           \"ps\": [\"host4:2222\", \"host5:2222\"]}\n",
       "```\n",
       "\n",
       "Example of `TF_CONFIG` for chief training worker (must have one and only one):\n",
       "```\n",
       "# This should be a JSON string, which is set as environment variable. Usually\n",
       "# the cluster manager handles that.\n",
       "TF_CONFIG='{\n",
       "    \"cluster\": {\n",
       "        \"chief\": [\"host0:2222\"],\n",
       "        \"worker\": [\"host1:2222\", \"host2:2222\", \"host3:2222\"],\n",
       "        \"ps\": [\"host4:2222\", \"host5:2222\"]\n",
       "    },\n",
       "    \"task\": {\"type\": \"chief\", \"index\": 0}\n",
       "}'\n",
       "```\n",
       "Note that the chief worker also does the model training job, similar to other\n",
       "non-chief training workers (see next paragraph). In addition to the model\n",
       "training, it manages some extra work, e.g., checkpoint saving and restoring,\n",
       "writing summaries, etc.\n",
       "\n",
       "Example of `TF_CONFIG` for non-chief training worker (optional, could be\n",
       "multiple):\n",
       "```\n",
       "# This should be a JSON string, which is set as environment variable. Usually\n",
       "# the cluster manager handles that.\n",
       "TF_CONFIG='{\n",
       "    \"cluster\": {\n",
       "        \"chief\": [\"host0:2222\"],\n",
       "        \"worker\": [\"host1:2222\", \"host2:2222\", \"host3:2222\"],\n",
       "        \"ps\": [\"host4:2222\", \"host5:2222\"]\n",
       "    },\n",
       "    \"task\": {\"type\": \"worker\", \"index\": 0}\n",
       "}'\n",
       "```\n",
       "where the `task.index` should be set as 0, 1, 2, in this example, respectively\n",
       "for non-chief training workers.\n",
       "\n",
       "Example of `TF_CONFIG` for parameter server, aka ps (could be multiple):\n",
       "```\n",
       "# This should be a JSON string, which is set as environment variable. Usually\n",
       "# the cluster manager handles that.\n",
       "TF_CONFIG='{\n",
       "    \"cluster\": {\n",
       "        \"chief\": [\"host0:2222\"],\n",
       "        \"worker\": [\"host1:2222\", \"host2:2222\", \"host3:2222\"],\n",
       "        \"ps\": [\"host4:2222\", \"host5:2222\"]\n",
       "    },\n",
       "    \"task\": {\"type\": \"ps\", \"index\": 0}\n",
       "}'\n",
       "```\n",
       "where the `task.index` should be set as 0 and 1, in this example, respectively\n",
       "for parameter servers.\n",
       "\n",
       "Example of `TF_CONFIG` for evaluator task. Evaluator is a special task that is\n",
       "not part of the training cluster. There could be only one. It is used for\n",
       "model evaluation.\n",
       "```\n",
       "# This should be a JSON string, which is set as environment variable. Usually\n",
       "# the cluster manager handles that.\n",
       "TF_CONFIG='{\n",
       "    \"cluster\": {\n",
       "        \"chief\": [\"host0:2222\"],\n",
       "        \"worker\": [\"host1:2222\", \"host2:2222\", \"host3:2222\"],\n",
       "        \"ps\": [\"host4:2222\", \"host5:2222\"]\n",
       "    },\n",
       "    \"task\": {\"type\": \"evaluator\", \"index\": 0}\n",
       "}'\n",
       "```\n",
       "\n",
       "Args:\n",
       "  estimator: An `Estimator` instance to train and evaluate.\n",
       "  train_spec: A `TrainSpec` instance to specify the training specification.\n",
       "  eval_spec: A `EvalSpec` instance to specify the evaluation and export\n",
       "    specification.\n",
       "\n",
       "Raises:\n",
       "  ValueError: if environment variable `TF_CONFIG` is incorrectly set.\n",
       "\u001b[0;31mFile:\u001b[0m      /anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\n",
       "\u001b[0;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.estimator.train_and_evaluate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 600 secs (eval_spec.throttle_secs) or training is finished.\n",
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:691: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.7347924, step = 1\n",
      "INFO:tensorflow:Loss for final step: 0.7347924.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:07:57\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-1\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:07:57\n",
      "INFO:tensorflow:Saving dict for global step 1: accuracy = 0.6023857, global_step = 1, loss = 0.68919784\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-1\n",
      "INFO:tensorflow:Saving checkpoints for 2 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.73997915, step = 2\n",
      "INFO:tensorflow:Loss for final step: 0.73997915.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:07:58\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-2\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:07:59\n",
      "INFO:tensorflow:Saving dict for global step 2: accuracy = 0.5964215, global_step = 2, loss = 0.6890746\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-2\n",
      "INFO:tensorflow:Saving checkpoints for 3 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.6606862, step = 3\n",
      "INFO:tensorflow:Loss for final step: 0.6606862.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:00\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-3\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:00\n",
      "INFO:tensorflow:Saving dict for global step 3: accuracy = 0.8111332, global_step = 3, loss = 0.6639196\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-3\n",
      "INFO:tensorflow:Saving checkpoints for 4 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.7843801, step = 4\n",
      "INFO:tensorflow:Loss for final step: 0.7843801.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:02\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-4\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:02\n",
      "INFO:tensorflow:Saving dict for global step 4: accuracy = 0.86282307, global_step = 4, loss = 0.65786356\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-4\n",
      "INFO:tensorflow:Saving checkpoints for 5 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.7475788, step = 5\n",
      "INFO:tensorflow:Loss for final step: 0.7475788.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:03\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-5\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:04\n",
      "INFO:tensorflow:Saving dict for global step 5: accuracy = 0.7037773, global_step = 5, loss = 0.67555577\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-5\n",
      "INFO:tensorflow:Saving checkpoints for 6 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.67512524, step = 6\n",
      "INFO:tensorflow:Loss for final step: 0.67512524.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:05\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-6\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:05\n",
      "INFO:tensorflow:Saving dict for global step 6: accuracy = 0.3280318, global_step = 6, loss = 0.71358466\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-6\n",
      "INFO:tensorflow:Saving checkpoints for 7 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.73671436, step = 7\n",
      "INFO:tensorflow:Loss for final step: 0.73671436.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:07\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-7\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:07\n",
      "INFO:tensorflow:Saving dict for global step 7: accuracy = 0.24254473, global_step = 7, loss = 0.72431904\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-7\n",
      "INFO:tensorflow:Saving checkpoints for 8 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.73455215, step = 8\n",
      "INFO:tensorflow:Loss for final step: 0.73455215.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:08\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-8\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:09\n",
      "INFO:tensorflow:Saving dict for global step 8: accuracy = 0.4055666, global_step = 8, loss = 0.7030625\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-8\n",
      "INFO:tensorflow:Saving checkpoints for 9 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.67545277, step = 9\n",
      "INFO:tensorflow:Loss for final step: 0.67545277.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:10\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-9\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:10\n",
      "INFO:tensorflow:Saving dict for global step 9: accuracy = 0.38767394, global_step = 9, loss = 0.70578367\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-9\n",
      "INFO:tensorflow:Saving checkpoints for 10 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.64392006, step = 10\n",
      "INFO:tensorflow:Loss for final step: 0.64392006.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:12\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-10\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:12\n",
      "INFO:tensorflow:Saving dict for global step 10: accuracy = 0.22664016, global_step = 10, loss = 0.7302296\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-10\n",
      "INFO:tensorflow:Saving checkpoints for 11 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.60729796, step = 11\n",
      "INFO:tensorflow:Loss for final step: 0.60729796.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:14\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-11\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:14\n",
      "INFO:tensorflow:Saving dict for global step 11: accuracy = 0.045725647, global_step = 11, loss = 0.7769992\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-11\n",
      "INFO:tensorflow:Saving checkpoints for 12 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.63827944, step = 12\n",
      "INFO:tensorflow:Loss for final step: 0.63827944.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:15\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-12\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:16\n",
      "INFO:tensorflow:Saving dict for global step 12: accuracy = 0.007952286, global_step = 12, loss = 0.84138393\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-12\n",
      "INFO:tensorflow:Saving checkpoints for 13 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.49378422, step = 13\n",
      "INFO:tensorflow:Loss for final step: 0.49378422.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:17\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-13\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:17\n",
      "INFO:tensorflow:Saving dict for global step 13: accuracy = 0.007952286, global_step = 13, loss = 0.92631227\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-13\n",
      "INFO:tensorflow:Saving checkpoints for 14 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.44584358, step = 14\n",
      "INFO:tensorflow:Loss for final step: 0.44584358.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:19\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-14\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:19\n",
      "INFO:tensorflow:Saving dict for global step 14: accuracy = 0.007952286, global_step = 14, loss = 1.0284654\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-14\n",
      "INFO:tensorflow:Saving checkpoints for 15 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.1215827, step = 15\n",
      "INFO:tensorflow:Loss for final step: 1.1215827.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:20\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-15\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:20\n",
      "INFO:tensorflow:Saving dict for global step 15: accuracy = 0.007952286, global_step = 15, loss = 1.0673176\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-15\n",
      "INFO:tensorflow:Saving checkpoints for 16 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.3565632, step = 16\n",
      "INFO:tensorflow:Loss for final step: 1.3565632.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:22\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-16\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:22\n",
      "INFO:tensorflow:Saving dict for global step 16: accuracy = 0.007952286, global_step = 16, loss = 1.0267779\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-16\n",
      "INFO:tensorflow:Saving checkpoints for 17 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.42189503, step = 17\n",
      "INFO:tensorflow:Loss for final step: 0.42189503.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:23\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-17\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:24\n",
      "INFO:tensorflow:Saving dict for global step 17: accuracy = 0.007952286, global_step = 17, loss = 1.0114423\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-17\n",
      "INFO:tensorflow:Saving checkpoints for 18 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.3420641, step = 18\n",
      "INFO:tensorflow:Loss for final step: 1.3420641.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:25\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-18\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:26\n",
      "INFO:tensorflow:Saving dict for global step 18: accuracy = 0.007952286, global_step = 18, loss = 0.95294863\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-18\n",
      "INFO:tensorflow:Saving checkpoints for 19 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.0802993, step = 19\n",
      "INFO:tensorflow:Loss for final step: 1.0802993.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:27\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-19\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:27\n",
      "INFO:tensorflow:Saving dict for global step 19: accuracy = 0.007952286, global_step = 19, loss = 0.8648052\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-19\n",
      "INFO:tensorflow:Saving checkpoints for 20 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.89248884, step = 20\n",
      "INFO:tensorflow:Loss for final step: 0.89248884.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:29\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-20\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:29\n",
      "INFO:tensorflow:Saving dict for global step 20: accuracy = 0.027833002, global_step = 20, loss = 0.7798961\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-20\n",
      "INFO:tensorflow:Saving checkpoints for 21 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.59791523, step = 21\n",
      "INFO:tensorflow:Loss for final step: 0.59791523.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:30\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-21\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:30\n",
      "INFO:tensorflow:Saving dict for global step 21: accuracy = 0.1471173, global_step = 21, loss = 0.7320964\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-21\n",
      "INFO:tensorflow:Saving checkpoints for 22 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.8022436, step = 22\n",
      "INFO:tensorflow:Loss for final step: 0.8022436.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:32\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-22\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:32\n",
      "INFO:tensorflow:Saving dict for global step 22: accuracy = 0.57057655, global_step = 22, loss = 0.6831123\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-22\n",
      "INFO:tensorflow:Saving checkpoints for 23 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.6283195, step = 23\n",
      "INFO:tensorflow:Loss for final step: 0.6283195.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:33\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-23\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:34\n",
      "INFO:tensorflow:Saving dict for global step 23: accuracy = 0.95427436, global_step = 23, loss = 0.6345669\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-23\n",
      "INFO:tensorflow:Saving checkpoints for 24 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.7709839, step = 24\n",
      "INFO:tensorflow:Loss for final step: 0.7709839.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:35\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-24\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:35\n",
      "INFO:tensorflow:Saving dict for global step 24: accuracy = 0.9860835, global_step = 24, loss = 0.61075145\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-24\n",
      "INFO:tensorflow:Saving checkpoints for 25 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.9256531, step = 25\n",
      "INFO:tensorflow:Loss for final step: 0.9256531.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:37\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-25\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:37\n",
      "INFO:tensorflow:Saving dict for global step 25: accuracy = 0.98807156, global_step = 25, loss = 0.61146563\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-25\n",
      "INFO:tensorflow:Saving checkpoints for 26 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.58076215, step = 26\n",
      "INFO:tensorflow:Loss for final step: 0.58076215.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:38\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-26\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:39\n",
      "INFO:tensorflow:Saving dict for global step 26: accuracy = 0.9900596, global_step = 26, loss = 0.60190123\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-26\n",
      "INFO:tensorflow:Saving checkpoints for 27 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.58699, step = 27\n",
      "INFO:tensorflow:Loss for final step: 0.58699.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:41\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-27\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:41\n",
      "INFO:tensorflow:Saving dict for global step 27: accuracy = 0.9920477, global_step = 27, loss = 0.576448\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-27\n",
      "INFO:tensorflow:Saving checkpoints for 28 into logs/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.44741333, step = 28\n",
      "INFO:tensorflow:Loss for final step: 0.44741333.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-16-01:08:43\n",
      "INFO:tensorflow:Restoring parameters from logs/model.ckpt-28\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-16-01:08:43\n",
      "INFO:tensorflow:Saving dict for global step 28: accuracy = 0.9920477, global_step = 28, loss = 0.5438922\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0ef20931c75f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(estimator, train_spec, eval_spec)\u001b[0m\n\u001b[1;32m    430\u001b[0m       config.task_type != run_config_lib.TaskType.EVALUATOR):\n\u001b[1;32m    431\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running training and evaluation locally (non-distributed).'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m     \u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/training.py\u001b[0m in \u001b[0;36mrun_local\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    609\u001b[0m           \u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m           \u001b[0mmax_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m           hooks=train_hooks)\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Final export signal: For any eval result with global_step >= train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    741\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 743\u001b[0;31m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[1;32m    744\u001b[0m       \u001b[0;31m# Check if the user created a loss summary, and add one if they didn't.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m       \u001b[0;31m# We assume here that the summary is called 'loss'. If it is not, we will\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'config'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_fn_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fn_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_fn_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEstimatorSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-cfc3d7e3843a>\u001b[0m in \u001b[0;36mmodel_fn\u001b[0;34m(features, labels, mode, params)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pooling1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# 15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pooling1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(inputs, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, trainable, name, reuse)\u001b[0m\n\u001b[1;32m    409\u001b[0m       \u001b[0m_reuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m       _scope=name)\n\u001b[0;32m--> 411\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    760\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \"\"\"\n\u001b[0;32m--> 762\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m   def _add_inbound_node(self,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0min_deferred_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             raise ValueError('A layer\\'s `call` method should return a Tensor '\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m         name=self.name)\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_conv1d\u001b[0;34m(self, input, filter, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m    178\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_conv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     return conv1d(value=input, filters=filter, stride=strides, padding=padding,\n\u001b[0;32m--> 180\u001b[0;31m                   data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m    181\u001b[0m   \u001b[0;31m# pylint: enable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv1d\u001b[0;34m(value, filters, stride, padding, use_cudnn_on_gpu, data_format, name)\u001b[0m\n\u001b[1;32m   2311\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_format must be \\\"NHWC\\\" or \\\"NCHW\\\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2313\u001b[0;31m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspatial_start_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2314\u001b[0m     \u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2315\u001b[0m     result = gen_nn_ops.conv2d(value, filters, strides, padding,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(input, axis, name, dim)\u001b[0m\n\u001b[1;32m    190\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"can't specify both 'dim' and 'axis'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36m_expand_dims\u001b[0;34m(input, axis, name)\u001b[0m\n\u001b[1;32m   1306\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 1308\u001b[0;31m         \"ExpandDims\", input=input, dim=axis, name=name)\n\u001b[0m\u001b[1;32m   1309\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3160\u001b[0m         op_def=op_def)\n\u001b[1;32m   3161\u001b[0m     self._create_op_helper(ret, compute_shapes=compute_shapes,\n\u001b[0;32m-> 3162\u001b[0;31m                            compute_device=compute_device)\n\u001b[0m\u001b[1;32m   3163\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[0;34m(self, op, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   3206\u001b[0m     \u001b[0;31m# compute_shapes argument.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3207\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3208\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3209\u001b[0m     \u001b[0;31m# TODO(b/XXXX): move to Operation.__init__ once _USE_C_API flag is removed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3210\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2425\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs_c_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2426\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2427\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_set_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_set_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2398\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2400\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2401\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2402\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2329\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2330\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2331\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2332\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    684\u001b[0m       output = pywrap_tensorflow.RunCppShapeInference(\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No shape inference function exists for op\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tf.estimator.train_and_evaluate(model, trainspec, evalspec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
