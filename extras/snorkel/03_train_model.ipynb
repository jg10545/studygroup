{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Training a model\n",
    "\n",
    "This part will look pretty generic- the only really `snorkel`-specific thing is that we'll randomly sample labels during training using the probabilistic labels from the last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load our preprocessed text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "844782"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"groupname_preprocessed_full.csv\")\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>end</th>\n",
       "      <th>eventid</th>\n",
       "      <th>label</th>\n",
       "      <th>labeled_sentence</th>\n",
       "      <th>name</th>\n",
       "      <th>sentence</th>\n",
       "      <th>start</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "      <td>197001010002</td>\n",
       "      <td>0</td>\n",
       "      <td>1/1/1970: Unknown ENTSTART African American E...</td>\n",
       "      <td>african american</td>\n",
       "      <td>1/1/1970: Unknown African American assailants...</td>\n",
       "      <td>19</td>\n",
       "      <td>NORP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>197001010002</td>\n",
       "      <td>0</td>\n",
       "      <td>1/1/1970: Unknown African American assailants...</td>\n",
       "      <td>cairo</td>\n",
       "      <td>1/1/1970: Unknown African American assailants...</td>\n",
       "      <td>95</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110</td>\n",
       "      <td>197001010002</td>\n",
       "      <td>0</td>\n",
       "      <td>1/1/1970: Unknown African American assailants...</td>\n",
       "      <td>illinois</td>\n",
       "      <td>1/1/1970: Unknown African American assailants...</td>\n",
       "      <td>102</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>197001010002</td>\n",
       "      <td>0</td>\n",
       "      <td>1/1/1970: Unknown African American assailants...</td>\n",
       "      <td>united states</td>\n",
       "      <td>1/1/1970: Unknown African American assailants...</td>\n",
       "      <td>112</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39</td>\n",
       "      <td>197001010002</td>\n",
       "      <td>0</td>\n",
       "      <td>There were no casualties, however, ENTSTART o...</td>\n",
       "      <td>one</td>\n",
       "      <td>There were no casualties, however, one bullet...</td>\n",
       "      <td>36</td>\n",
       "      <td>CARDINAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   end       eventid  label  \\\n",
       "0   35  197001010002      0   \n",
       "1  100  197001010002      0   \n",
       "2  110  197001010002      0   \n",
       "3  125  197001010002      0   \n",
       "4   39  197001010002      0   \n",
       "\n",
       "                                    labeled_sentence              name  \\\n",
       "0   1/1/1970: Unknown ENTSTART African American E...  african american   \n",
       "1   1/1/1970: Unknown African American assailants...             cairo   \n",
       "2   1/1/1970: Unknown African American assailants...          illinois   \n",
       "3   1/1/1970: Unknown African American assailants...     united states   \n",
       "4   There were no casualties, however, ENTSTART o...               one   \n",
       "\n",
       "                                            sentence  start      type  \n",
       "0   1/1/1970: Unknown African American assailants...     19      NORP  \n",
       "1   1/1/1970: Unknown African American assailants...     95       GPE  \n",
       "2   1/1/1970: Unknown African American assailants...    102       GPE  \n",
       "3   1/1/1970: Unknown African American assailants...    112       GPE  \n",
       "4   There were no casualties, however, one bullet...     36  CARDINAL  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And our probalistic labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(844782,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_probs = np.fromfile(\"pos_probs.numpy\")\n",
    "pos_probs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's divide these into training and validation sets. \n",
    "\n",
    "* For train, use probabilistic labels\n",
    "* For test, use actual ground truth since we have it\n",
    "* I'm discarding any training points set to 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(pos_probs.size)\n",
    "train_indices = indices % 10 != 0\n",
    "test_indices = indices % 10 == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_strings = df.labeled_sentence.values[train_indices]\n",
    "train_probs = pos_probs[train_indices]\n",
    "\n",
    "train_strings = train_strings[train_probs != 0.5]\n",
    "train_probs = train_probs[train_probs != 0.5]\n",
    "\n",
    "test_strings = df.labeled_sentence.values[test_indices]\n",
    "# for test let's use the actual ground truth\n",
    "test_labels = df.label.values[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "549477"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build input pipelines\n",
    "\n",
    "The only non-standard thing is the training generator- every time it's called, it randomly chooses a value for the label (0 or 1) using the `snorkel` label as a Bernoulli probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=15000\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=vocab_size, lower=True, oov_token=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(train_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 1/1/1970: Unknown African American assailants fired several bullets at police headquarters in ENTSTART Cairo ENTEND , Illinois, United States '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_strings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = tokenizer.texts_to_sequences(train_strings)\n",
    "test_x = tokenizer.texts_to_sequences(test_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[400,\n",
       " 400,\n",
       " 752,\n",
       " 67,\n",
       " 355,\n",
       " 713,\n",
       " 10,\n",
       " 84,\n",
       " 301,\n",
       " 2703,\n",
       " 13,\n",
       " 27,\n",
       " 336,\n",
       " 4,\n",
       " 2,\n",
       " 776,\n",
       " 3,\n",
       " 1806,\n",
       " 133,\n",
       " 215]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.hist([len(x) for x in train_x], bins=50);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "steps_per_epoch = int(len(pos_probs)/batch_size)\n",
    "\n",
    "def _train_generator():\n",
    "    while True:\n",
    "        for i in range(len(train_x)):\n",
    "            x = np.array(train_x[i], dtype=np.int64)\n",
    "            y = np.random.binomial(1, train_probs[i])\n",
    "            yield x,y\n",
    "            \n",
    "train_ds = tf.data.Dataset.from_generator(_train_generator, \n",
    "                                         (tf.int64, tf.int64),\n",
    "                                         ((None), ()))\n",
    "train_ds = train_ds.shuffle(50000)\n",
    "train_ds = train_ds.padded_batch(batch_size,\n",
    "                                padded_shapes=([None], []))\n",
    "train_ds = train_ds.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps = int(len(test_labels)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _test_generator():\n",
    "    for i in range(len(test_x)):\n",
    "        yield np.array(test_x[i], dtype=np.int64), test_labels[i]\n",
    "        \n",
    "test_ds = tf.data.Dataset.from_generator(_test_generator, \n",
    "                                         (tf.int64, tf.int64),\n",
    "                                         ((None), ()))\n",
    "test_ds = test_ds.padded_batch(batch_size,\n",
    "                                padded_shapes=([None], []))\n",
    "test_ds = test_ds.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DatasetV1Adapter shapes: ((?, ?), (?,)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: (512, 67)\n",
      "y: (512,)\n"
     ]
    }
   ],
   "source": [
    "it = train_ds.make_one_shot_iterator().get_next()\n",
    "with tf.Session() as sess:\n",
    "    foo = sess.run(it)\n",
    "    \n",
    "print(\"x:\", foo[0].shape)\n",
    "print(\"y:\", foo[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'bidirectional_1/concat:0' shape=(?, ?, 128) dtype=float32>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpt = tf.keras.layers.Input([None])\n",
    "rnn_dim = 64\n",
    "\n",
    "embed_layer = tf.keras.layers.Embedding(vocab_size, 25)\n",
    "embedded = embed_layer(inpt)\n",
    "\n",
    "lstm = tf.keras.layers.LSTM(rnn_dim, return_sequences=True)\n",
    "bidir = tf.keras.layers.Bidirectional(lstm)\n",
    "rnn_out = bidir(embedded)\n",
    "rnn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_inpt = tf.keras.layers.Input((None, rnn_dim*2))\n",
    "# compute a weight for the vector at each step\n",
    "attention_logits = tf.keras.layers.Dense(1)(attention_inpt)\n",
    "# swap so STEPS are last instead of CHANNELS\n",
    "attention_swapped = tf.keras.layers.Lambda(\n",
    "    lambda x: tf.transpose(x, [0,2,1]), name=\"swap_axes\")(attention_logits)\n",
    "# use softmax to normalize\n",
    "attention_normed = tf.keras.layers.Activation(\n",
    "    tf.keras.activations.softmax, name=\"softmax_normalize\")(attention_swapped)\n",
    "# swap axes back to channels-last\n",
    "attention_swapped_back = tf.keras.layers.Lambda(\n",
    "    lambda x: tf.transpose(x, [0,2,1]), name=\"swapped_back\")(attention_normed)\n",
    "# multiply attention weights with output vectors\n",
    "attention_weighted_rnn_outs = tf.keras.layers.Multiply(\n",
    "    name=\"scaled_rnn_outs\")([attention_inpt, attention_swapped_back])\n",
    "# sum to reduce the tensor rank by 1; now we have a single vector that's \n",
    "# a weighted sum of RNN outputs\n",
    "attention_out = tf.keras.layers.Lambda(\n",
    "    lambda x: tf.reduce_sum(x, axis=1), name=\"rnn_weighted_sum\")(attention_weighted_rnn_outs)\n",
    "# also save weights so we can inspect later\n",
    "attention_weights = tf.keras.layers.Lambda(\n",
    "    lambda x: tf.reduce_sum(x, axis=2), name=\"attention_weights\")(attention_swapped_back)\n",
    "\n",
    "attention_model = tf.keras.Model(attention_inpt,\n",
    "                                [attention_out, attention_weights],\n",
    "                                name=\"attention_mechanism\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/joe/anaconda3/envs/snorkel/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "attention_result, weights = attention_model(rnn_out)\n",
    "dense = tf.keras.layers.Dense(256, \n",
    "                              activation=tf.keras.activations.relu)(attention_result)\n",
    "dropout = tf.keras.layers.Dropout(0.5)(dense)\n",
    "dense2 = tf.keras.layers.Dense(256, \n",
    "                              activation=tf.keras.activations.relu)(dropout)\n",
    "dropout2 = tf.keras.layers.Dropout(0.5)(dense2)\n",
    "output = tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid,\n",
    "                              name=\"output\")(dropout2)\n",
    "\n",
    "model = tf.keras.Model(inpt, [output, weights])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 25)          375000    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, None, 128)         46080     \n",
      "_________________________________________________________________\n",
      "attention_mechanism (Model)  [(None, 128), (None, None 129       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 520,282\n",
      "Trainable params: 520,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'output/Sigmoid:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'attention_mechanism/attention_weights/Sum:0' shape=(?, ?) dtype=float32>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Output \"attention_mechanism\" missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to \"attention_mechanism\".\n"
     ]
    }
   ],
   "source": [
    "model.compile(tf.keras.optimizers.RMSprop(1e-3),\n",
    "             loss={\"output\":tf.keras.losses.binary_crossentropy},\n",
    "             metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/joe/anaconda3/envs/snorkel/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/joe/anaconda3/envs/snorkel/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "1649/1649 [==============================] - 410s 249ms/step - loss: 0.4899 - output_loss: 0.4899 - output_acc: 0.8024 - val_loss: 0.4247 - val_output_loss: 0.4247 - val_output_acc: 0.8171\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8751b4a4a8>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, batch_size=batch_size,\n",
    "         epochs=1, steps_per_epoch=steps_per_epoch,\n",
    "         validation_data=test_ds, validation_steps=test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
